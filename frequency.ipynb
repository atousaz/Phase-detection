{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path='../raw/'\n",
    "date_list=['2021-04-13','2021-04-14','2021-04-15','2021-04-16']\n",
    "\n",
    "meta=pd.read_csv('../meta/Foothill_detectors.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in date_list:\n",
    "    \n",
    "    df=pd.read_csv(path+i+'.csv')\n",
    "    df=df[df['intersection'].isin(meta.SignalID.unique())]\n",
    "    df['time']=pd.to_datetime(df['time'])\n",
    "    df=df.rename(columns={'intersection':'signal','code':'event','para':'parameter', 'time':'datetime'})\n",
    "\n",
    "    df['datetime']=pd.to_datetime(df['datetime'])\n",
    "\n",
    "    cycle_df=pd.read_csv('../occupancy/'+i+'/'+'cycle_df_'+i+'.csv', index_col=[0])\n",
    "\n",
    "\n",
    "    cycle_df=cycle_df[cycle_df['cycle_lenght']==150]\n",
    "    cycle_df=cycle_df.sort_values(['signal','start_cycle']) \n",
    "    cycle_df=cycle_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "    grouped=cycle_df.groupby(['signal'])\n",
    "    id_cycle_df=pd.DataFrame([])\n",
    "    for sets , data in grouped:\n",
    "        data=data.sort_values(['start_cycle']).reset_index(drop=True)\n",
    "        data['cycle_id']=data.index\n",
    "        id_cycle_df=id_cycle_df.append(data)\n",
    "\n",
    "    id_cycle_df=id_cycle_df.sort_values(['signal','start_cycle']).reset_index(drop=True)\n",
    "    id_cycle_df['unique_cycle_id']=id_cycle_df.index\n",
    "    id_cycle_df.to_csv(i+'/'+'id_cycle_df'+'_'+i+'.csv')\n",
    "\n",
    "    detector_df=pd.read_csv('../occupancy/'+i+'/'+'detector_df'+i+'.csv', index_col=[0])\n",
    "    \n",
    "    import sqlite3\n",
    "    #Make the db in memory\n",
    "    frequency_db = sqlite3.connect(':memory:')\n",
    "    #write the tables\n",
    "    detector_df.to_sql('detector', frequency_db, index=False)\n",
    "    id_cycle_df.to_sql('cycle_df', frequency_db, index=False)\n",
    "\n",
    "    qry = '''\n",
    "    select  \n",
    "        detector.*\n",
    "        ,cycle_df.start_cycle\n",
    "        ,cycle_df.end_cycle\n",
    "        ,cycle_df.signal\n",
    "        ,cycle_df.cycle_id\n",
    "        ,cycle_df.unique_cycle_id\n",
    "    from detector \n",
    "        join cycle_df  using(signal)\n",
    "        WHERE\n",
    "        detector_on_start between start_cycle and end_cycle\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "    df_query_frequency = pd.read_sql_query(qry, frequency_db)\n",
    "    df_query_frequency = df_query_frequency.loc[:,~df_query_frequency.columns.duplicated()]\n",
    "\n",
    "    df_query_frequency['start_cycle']=pd.to_datetime(df_query_frequency['start_cycle'])\n",
    "    df_query_frequency['end_cycle']=pd.to_datetime(df_query_frequency['end_cycle'])\n",
    "    df_query_frequency['detector_on_start']=pd.to_datetime(df_query_frequency['detector_on_start'])\n",
    "    df_query_frequency['detector_on_end']=pd.to_datetime(df_query_frequency['detector_on_end'])\n",
    "\n",
    "\n",
    "    df_query_frequency.to_csv(i+'/'+'df_query_frequency'+'_'+i+'.csv')\n",
    "    df_query_frequency['start_cycle']=pd.to_datetime(df_query_frequency['start_cycle'])\n",
    "    df_query_frequency['end_cycle']=pd.to_datetime(df_query_frequency['end_cycle'])\n",
    "    df_query_frequency['detector_on_start']=pd.to_datetime(df_query_frequency['detector_on_start'])\n",
    "    df_query_frequency['detector_on_end']=pd.to_datetime(df_query_frequency['detector_on_end'])\n",
    "\n",
    "\n",
    "    df_query_frequency['start_chunk']=np.ceil((df_query_frequency['detector_on_start']-df_query_frequency['start_cycle']).dt.total_seconds()/5)\n",
    "    # because of ceiling issue , when detector on time is the same as cycle start time it will give 0 we push that to 1 \n",
    "    # manually below\n",
    "    df_query_frequency['start_chunk']=np.where(df_query_frequency['start_chunk']==0,1,df_query_frequency['start_chunk'])\n",
    "\n",
    "    df_query_frequency.to_csv(i+'/'+'df_query_frequency'+'_'+i+'.csv')\n",
    "\n",
    "    f=df_query_frequency.groupby(['signal','detector_parameter','start_cycle','end_cycle','cycle_id','unique_cycle_id','start_chunk'])['unique_detector_id'].count().reset_index().sort_values(['unique_detector_id'],ascending=False)\n",
    "    f=f.rename(columns={'unique_detector_id':'count'})\n",
    "\n",
    "    f=f.merge(meta, how='left', left_on=['signal','detector_parameter'], right_on=['SignalID','DetChannel']).drop(['SignalID'],axis=1)\n",
    "    f.to_csv(i+'/'+'frequency_v1'+'_'+i+'.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
